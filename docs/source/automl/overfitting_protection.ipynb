{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting\n",
    "\n",
    "The ultimate goal of machine learning is to make accurate predictions on unseen data. EvalML aims to help you build a model that will perform as you expect once it is deployed in to the real world.\n",
    "\n",
    "One of the benefits of using EvalML to build models is that it provides data checks to ensure you are building pipelines that will perform reliably in the future. This page describes the various ways EvalML helps you avoid overfitting to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Label Leakage\n",
    "\n",
    "A common problem is having features that include information from your label in your training data. By default, EvalML will provide a warning when it detects this may be the case.\n",
    "\n",
    "Let's set up a simple example to demonstrate what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'leaked_feature' is 95.0% or more correlated with the target\n",
      "Column 'leaked_feature_2' is 95.0% or more correlated with the target\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evalml.data_checks import LabelLeakageDataCheck\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"leaked_feature\": [6, 6, 10, 5, 5, 11, 5, 10, 11, 4],\n",
    "    \"leaked_feature_2\": [3, 2.5, 5, 2.5, 3, 5.5, 2, 5, 5.5, 2],\n",
    "    \"valid_feature\": [3, 1, 3, 2, 4, 6, 1, 3, 3, 11]\n",
    "})\n",
    "\n",
    "y = pd.Series([1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
    "\n",
    "label_leakage_check = LabelLeakageDataCheck()\n",
    "messages = label_leakage_check.validate(X, y)\n",
    "for message in messages:\n",
    "    print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, EvalML warned about the input features `leaked_feature` and `leak_feature_2`, which are both very closely correlated with the label we are trying to predict.\n",
    "\n",
    "The second way to find features that may be leaking label information is to look at the top features of the model after running an AutoML search. As we can see below, the top features in our model are the 2 leaked features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'leaked_feature' is 95.0% or more correlated with the target\n",
      "Column 'leaked_feature_2' is 95.0% or more correlated with the target\n",
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Searching up to 1 pipelines. \n",
      "Allowed model families: linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05e0be032e74120b7ce0caa4aa215cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.688\n",
      "\n",
      "Search finished after 00:00            \n",
      "Best pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Best pipeline Log Loss Binary: 0.687686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leaked_feature</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaked_feature_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valid_feature</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "0    leaked_feature         0.0\n",
       "1  leaked_feature_2         0.0\n",
       "2     valid_feature         0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = evalml.AutoMLSearch(\n",
    "    problem_type='binary',\n",
    "    max_pipelines=1,\n",
    "    allowed_model_families=[\"linear_model\"],\n",
    ")\n",
    "\n",
    "automl.search(X, y)\n",
    "best_pipeline = automl.best_pipeline\n",
    "best_pipeline.fit(X, y)\n",
    "best_pipeline.feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Perform cross-validation for pipeline evaluation\n",
    "\n",
    "By default, EvalML performs 3-fold cross validation when building pipelines. This means that it evaluates each pipeline 3 times using different sets of data for training and testing. In each trial, the data used for testing has no overlap from the data used for training.\n",
    "\n",
    "While this is a good baseline approach, you can pass your own cross validation object to be used during modeling. The cross validation object can be any of the CV methods defined in [scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html) or use a compatible API.\n",
    "\n",
    "For example, if we wanted to do a time series split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Searching up to 1 pipelines. \n",
      "Allowed model families: catboost, xgboost, random_forest, linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659638cb3f584f8099ac3d48ef97f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.695\n",
      "\n",
      "Search finished after 00:00            \n",
      "Best pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Best pipeline Log Loss Binary: 0.694742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "automl = evalml.AutoMLSearch(\n",
    "    problem_type='binary',\n",
    "    data_split=TimeSeriesSplit(n_splits=6), \n",
    "    max_pipelines=1\n",
    ")\n",
    "\n",
    "automl.search(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we describe the 1 pipeline we built, we can see the scores for each of the 6 splits as determined by the cross-validation object we provided. We can also see the number of training examples per fold increased because we were using `TimeSeriesSplit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "* Mode Baseline Binary Classification Pipeline *\n",
      "************************************************\n",
      "\n",
      "Problem Type: Binary Classification\n",
      "Model Family: Baseline\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Baseline Classifier\n",
      "\t * strategy : random_weighted\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for Binary Classification problems.\n",
      "Total training time (including CV): 0.0 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  Accuracy Binary  Balanced Accuracy Binary    F1  Precision   AUC  MCC Binary # Training # Testing\n",
      "0                      0.880            0.358                     0.500 0.000      0.000 0.500       0.000     83.000    81.000\n",
      "1                      0.697            0.469                     0.500 0.000      0.000 0.500       0.000    164.000    81.000\n",
      "2                      0.697            0.333                     0.500 0.000      0.000 0.500       0.000    245.000    81.000\n",
      "3                      0.664            0.716                     0.500 0.835      0.716 0.500       0.000    326.000    81.000\n",
      "4                      0.619            0.790                     0.500 0.883      0.790 0.500       0.000    407.000    81.000\n",
      "5                      0.611            0.741                     0.500 0.851      0.741 0.500       0.000    488.000    81.000\n",
      "mean                   0.695            0.568                     0.500 0.428      0.374 0.500       0.000          -         -\n",
      "std                    0.098            0.205                     0.000 0.469      0.411 0.000       0.000          -         -\n",
      "coef of var            0.141            0.361                     0.000 1.096      1.097 0.000         inf          -         -\n"
     ]
    }
   ],
   "source": [
    "automl.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect unstable pipelines\n",
    "\n",
    "When we perform cross validation we are trying generate an estimate of pipeline performance. EvalML does this by taking the mean of the score across the folds. If the performance across the folds varies greatly, it is indicative the the estimated value may be unreliable. \n",
    "\n",
    "To protect the user against this, EvalML checks to see if the pipeline's performance has a variance between the different folds. EvalML triggers a warning if the \"coefficient of variance\" of the scores (the standard deviation divided by mean) of the pipelines scores exeeds .2.\n",
    "\n",
    "This warning will appear in the pipeline rankings under `high_variance_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Baseline Classifier': {'strategy': 'random_w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                 pipeline_name     score  \\\n",
       "0   0  Mode Baseline Binary Classification Pipeline  0.694742   \n",
       "\n",
       "   high_variance_cv                                         parameters  \n",
       "0             False  {'Baseline Classifier': {'strategy': 'random_w...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create holdout for model validation\n",
    "\n",
    "EvalML offers a method to quickly create an holdout validation set. A holdout validation set is data that is not used during the process of optimizing or training the model. You should only use this validation set once you've picked the final model you'd like to use.\n",
    "\n",
    "Below we create a holdout set of 20% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = evalml.demos.load_breast_cancer()\n",
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for F1. \n",
      "Greater score is better.\n",
      "\n",
      "Searching up to 3 pipelines. \n",
      "Allowed model families: catboost, xgboost, random_forest, linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353404b0ae1048d8b15a765c4128eb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/3) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.770\n",
      "(2/3) CatBoost Classifier w/ Simple Imputer    Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.974\n",
      "(3/3) XGBoost Classifier w/ Simple Imputer     Elapsed:00:10\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.970\n",
      "\n",
      "Search finished after 00:11            \n",
      "Best pipeline: CatBoost Classifier w/ Simple Imputer\n",
      "Best pipeline F1: 0.973947\n"
     ]
    }
   ],
   "source": [
    "automl = evalml.AutoMLSearch(problem_type='binary',\n",
    "                             objective=\"f1\",\n",
    "                             max_pipelines=3)\n",
    "automl.search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we can retrain the best pipeline on all of our training data and see how it performs compared to the estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('F1', 0.9793103448275863)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_holdout, y_holdout, [\"f1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
