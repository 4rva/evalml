{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting\n",
    "\n",
    "The ultimate goal of machine learning is to make accurate predictions on unseen data. One of the benefits of using EvalML to build models is that provides guardrails to ensure you are building pipelines that will perform reliably in the future.\n",
    "\n",
    "The sections on this page describe the various ways EvalML helps you avoid overfitting to your data. In the end, EvalML aims to help you build a model that will perform as you expect once it is deployed in to the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detects Label Leakage\n",
    "\n",
    "A common problem is having features that include information from your label in your training data. By default, will provide a warning when it detects this may be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for Precision. Greater score is better.\n",
      "\n",
      "Searching up to 1 pipelines. No time limit is set. Set one using max_time parameter.\n",
      "\n",
      "Possible model types: linear_model\n",
      "\n",
      "WARNING: Possible label leakage: leaked_feature, leaked_feature_2\n",
      "Testing LogisticRegression w/ imputation + scaling: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"leaked_feature\": [6, 6, 10, 5, 5, 11, 5, 10, 11, 4],\n",
    "    \"leaked_feature_2\": [3, 2.5, 5, 2.5, 3, 5.5, 2, 5, 5.5, 2],\n",
    "    \"correct_feature\": [3, 1, 3, 2, 4, 6, 1, 3, 3, 11]\n",
    "})\n",
    "\n",
    "y = pd.Series([1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
    "\n",
    "clf = evalml.AutoClassifier(\n",
    "    max_pipelines=1,\n",
    "    model_types=[\"linear_model\"],\n",
    "    detect_label_leakage=True,\n",
    ")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, EvalML warned about the input features \"leaked_feature\" and \"lead_feature_2\", which are both very closely correlated with the label we are trying to predct. If you'd like to turn this check off, set `detect_label_leakage=False`.\n",
    "\n",
    "The second way to find features that may be leaking label information is to look at the top features of the model. As we can see below, the top features in our model are the 2 leaked features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leaked_feature</td>\n",
       "      <td>-1.773115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaked_feature_2</td>\n",
       "      <td>-1.731261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>correct_feature</td>\n",
       "      <td>-0.247665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "0    leaked_feature   -1.773115\n",
       "1  leaked_feature_2   -1.731261\n",
       "2   correct_feature   -0.247665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline = clf.best_pipeline\n",
    "best_pipeline.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Peforms cross-validation for pipeline evaluation\n",
    "\n",
    "By default, EvalML performs 3-fold cross validation when building pipelines. This means that it evaluates each pipeline 3 times using different for training and testing. In each trial the data used for testing is has no overlap from the data used for training to avoid overfitting.\n",
    "\n",
    "While this is a good baseline approach, you can pass your own cross validation object to be used during modeling. The cross validation object can be any of the CV methods defined in [scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html) or use a compatible API.\n",
    "\n",
    "For example, if we wanted to do a time series split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for Precision. Greater score is better.\n",
      "\n",
      "Searching up to 1 pipelines. No time limit is set. Set one using max_time parameter.\n",
      "\n",
      "Possible model types: linear_model, random_forest, xgboost\n",
      "\n",
      "Testing XGBoost w/ imputation: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "clf = evalml.AutoClassifier(\n",
    "    cv=TimeSeriesSplit(n_splits=6), \n",
    "    max_pipelines=1\n",
    ")\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we describe the 1 pipeline we built, we can see the scores for each of the 6 splits as determined by the cross-validation object we provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************\u001b[0m\n",
      "\u001b[1m* Pipeline Description *\u001b[0m\n",
      "\u001b[1m************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost w/ imputation\n",
      "Model type: xgboost\n",
      "Objective: Precision (greater is better)\n",
      "Total training time (including CV): 0.6 seconds\n",
      "\n",
      "Parameters\n",
      "==========\n",
      "• eta: 0.5928446182250184\n",
      "• min_child_weight: 8.598391737229157\n",
      "• max_depth: 4\n",
      "• impute_strategy: most_frequent\n",
      "• percent_features: 0.6273280598181127\n",
      "\n",
      "Cross Validation\n",
      "=================\n",
      "               F1  Precision  Recall   AUC  Log Loss  # Training  # Testing\n",
      "0           0.822      0.974   0.822 0.950     0.578      83.000         81\n",
      "1           0.988      1.000   0.988 1.000     0.163     164.000         81\n",
      "2           0.972      0.964   0.972 0.968     0.134     245.000         81\n",
      "3           0.955      1.000   0.955 0.997     0.106     326.000         81\n",
      "4           0.968      1.000   0.968 0.998     0.116     407.000         81\n",
      "5           0.983      0.983   0.983 0.998     0.077     488.000         81\n",
      "mean        0.948      0.987   0.948 0.985     0.196     285.500         81\n",
      "std         0.063      0.016   0.063 0.021     0.190     151.537          0\n",
      "coef of var 0.066      0.016   0.066 0.021     0.969       0.531          0\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detects unstable pipelines\n",
    "\n",
    "When we perform cross validation we are trying generate an estimate of pipeline performance. EvalML does this by taking the mean of the score across the folds. If the performance across the folds varies greatly, it is indicative the the estimated value may be unreliable. \n",
    "\n",
    "To protect the user against this, EvalML check to see if performance of the pipeline has a high variance between different folds. It triggers a warning is the \"coeffient of variance\" of the scores (the standard deviation divided by mean) or the pipelines scores exeeds .2.\n",
    "\n",
    "This warning will appear in the pipeline rankings under `high_variance_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.986776</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    pipeline_name     score  high_variance_cv  \\\n",
       "0   0  XGBoostPipeline  0.986776             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'eta': 0.5928446182250184, 'min_child_weight'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create holdout for model validation\n",
    "\n",
    "EvalML offers method to quickly create an holdout validation set. A holdout validation set is data that is not used during the process of optmizing or training the model. You should only use this validation set once you've picked the final model you'd like to use.\n",
    "\n",
    "Below we create a holdout set of 20% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = evalml.demos.load_breast_cancer()\n",
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for Precision. Greater score is better.\n",
      "\n",
      "Searching up to 3 pipelines. No time limit is set. Set one using max_time parameter.\n",
      "\n",
      "Possible model types: linear_model, random_forest, xgboost\n",
      "\n",
      "Testing XGBoost w/ imputation: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]                     \n",
      "\n",
      "✔ Optimization finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.965669</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.965669</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 6.239401330891865, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.955733</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   0  LogisticRegressionPipeline  0.965669             False   \n",
       "1   1  LogisticRegressionPipeline  0.965669             False   \n",
       "2   2             XGBoostPipeline  0.955733             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "1  {'penalty': 'l2', 'C': 6.239401330891865, 'imp...  \n",
       "2  {'eta': 0.5928446182250184, 'min_child_weight'...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = evalml.AutoClassifier(\n",
    "    max_pipelines=3,\n",
    "    detect_label_leakage=True\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we can retrain the best pipeline on all of our training data and see how it performs compared to the estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726027397260274"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.best_pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_holdout, y_holdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
