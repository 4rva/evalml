{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default DataChecks in AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, AutoML will run the series of data checks in `DefaultDataChecks` when `automl.search()` is called to check that inputs are valid before running the search and fitting pipelines. Currently, `DefaultDataChecks` contains `HighlyNullDataCheck()`, `IDColumnsDataCheck()`, `LabelLeakageDataCheck()`. You can see the other available data checks under `evalml/data_checks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data checks return any warnings, those warnings will be logged, but the search will continue. However, if the data checks returns any error messages, `automl.search()` will raise a `ValueError` and quit before searching. This allows users to address any issues before running the potentially time-intensive search process. \n",
    "\n",
    "\n",
    "Below, we have some data that contain a lot of null values, causing `DefaultDataChecks` to log a warning \"Column 'D' is 95.0% or more null\" and \"Column 'id' is 100.0% or more likely to be an ID column\" when try to run the search below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'D' is 95.0% or more null\n",
      "Column 'id' is 100.0% or more likely to be an ID column\n",
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Searching up to 1 pipelines. \n",
      "Allowed model families: xgboost, catboost, random_forest, linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8886484e7a7343cf82235ffbed29022a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.694\n",
      "\n",
      "Search finished after 00:00            \n",
      "Best pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Best pipeline Log Loss Binary: 0.693523\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = pd.DataFrame(np.random.random((100, 5)), columns=[\"A\", \"B\", \"C\", \"D\", \"id\"])\n",
    "X.loc[:11, 'A'] = np.nan\n",
    "X.loc[:9, 'B'] = np.nan\n",
    "X.loc[:30, 'C'] = np.nan\n",
    "X.loc[:95, 'D'] = np.nan\n",
    "X.loc[:, 'id'] = range(100)\n",
    "y = pd.Series([0,1]*50)\n",
    "\n",
    "automl = evalml.AutoMLSearch(problem_type='binary', max_pipelines=1)\n",
    "automl.search(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the exact warning and/or error messages our data checks returned, we can access `automl.data_check_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'D' is 95.0% or more null\n",
      "Column 'id' is 100.0% or more likely to be an ID column\n"
     ]
    }
   ],
   "source": [
    "for message in automl.data_check_results:\n",
    "    print (message.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own DataCheck with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd prefer to pass in your own data check, you can do so by passing in a `DataChecks` object as the value for the `data_checks` parameter. Here, we've implemented our own custom data check which returns a list of `DataCheckError` objects if there are any columns that have zero variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.data_checks import DataCheck, DataChecks\n",
    "from evalml.data_checks.data_check_message import DataCheckError\n",
    "\n",
    "class ZeroVarianceDataCheck(DataCheck):\n",
    "    def validate(self, X, y):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        warning_msg = \"Column '{}' has zero variance\"\n",
    "        return [DataCheckError(warning_msg.format(column), self.name) for column in X.columns if len(X[column].unique()) == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now call `search()`, our error message will be logged and a `ValueError` will be raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'no_var' has zero variance\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data checks raised some warnings and/or errors. Please see `self.data_check_results` for more information or pass data_checks=EmptyDataChecks() to search() to disable data checking.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f0233162825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoMLSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pipelines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_checks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_checks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/evalml/evalml/automl/automl_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, X, y, data_checks, feature_types, raise_errors, show_iteration_plot)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDataCheckMessageType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_check_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data checks raised some warnings and/or errors. Please see `self.data_check_results` for more information or pass data_checks=EmptyDataChecks() to search() to disable data checking.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowed_pipelines\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data checks raised some warnings and/or errors. Please see `self.data_check_results` for more information or pass data_checks=EmptyDataChecks() to search() to disable data checking."
     ]
    }
   ],
   "source": [
    "data_checks = DataChecks(data_checks=[ZeroVarianceDataCheck()])\n",
    "\n",
    "X = pd.DataFrame({'no_var': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  'any_average_col': [2, 0, 1, 2, 1, 2, 0, 1, 2, 1],\n",
    "                  'another_average_col': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]})\n",
    "y = pd.Series([0,1,1,0,0,0,1,1,0,0])\n",
    "\n",
    "automl = evalml.AutoMLSearch(problem_type='binary', max_pipelines=1)\n",
    "automl.search(X, y, data_checks=data_checks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can access `self.data_check_results` to help us begin to address the issues raised by data checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'no_var' has zero variance\n"
     ]
    }
   ],
   "source": [
    "for message in automl.data_check_results:\n",
    "    print (message.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling DataChecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd prefer not to run any data checks before running search, you can provide an `EmptyDataChecks` instance to `search()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Searching up to 1 pipelines. \n",
      "Allowed model families: xgboost, catboost, random_forest, linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95e1cbfaecc4788bc13466462c9961b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.688\n",
      "\n",
      "Search finished after 00:00            \n",
      "Best pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Best pipeline Log Loss Binary: 0.687686\n"
     ]
    }
   ],
   "source": [
    "from evalml.data_checks import EmptyDataChecks\n",
    "\n",
    "X = pd.DataFrame({'no_var': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  'any_average_col': [2, 0, 1, 2, 1, 2, 0, 1, 2, 1],\n",
    "                  'another_average_col': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]})\n",
    "y = pd.Series([0,1,1,0,0,0,1,1,0,0])\n",
    "automl = evalml.AutoMLSearch(problem_type='binary', max_pipelines=1)\n",
    "automl.search(X, y, data_checks=EmptyDataChecks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we are using the same data as above, no data checks will be run and hence, the same input data we used above will not raise an error and continue with the search process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nbsphinx": {
   "allow_errors": true,
   "suppress_warnings": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
