{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Fraud Prediction Model with EvalML\n",
    "\n",
    "In this demo, we will build an optimized fraud prediction model using EvalML. To optimize the pipeline, we will set up an objective function based on some assumptions about our business. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml.objectives import FraudDetection\n",
    "from evalml.preprocessing import split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Number of Features\n",
      "Boolean                       1\n",
      "Categorical                   6\n",
      "Numeric                       5\n",
      "\n",
      "Number of training examples: 99992\n",
      "\n",
      "Labels\n",
      "False    84.82%\n",
      "True     15.18%\n",
      "Name: fraud, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X, y = evalml.demos.load_fraud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objective\n",
    "\n",
    "To make optimize the pipelines toward your specific business needs, you can set your own assumptions for the cost of fraud. These parameters are\n",
    "\n",
    "* `retry_percentage` - what percentage of customers will retry a transaction if it is declined?\n",
    "* `interchange_fee` - how much of each successfull transaction do you collect?\n",
    "* `fraud_payout_percentage` - how percentage of fraud will you be unable to collect\n",
    "\n",
    "Using these parameters, EvalML determines attempt to build a pipeline that will minimize the financial loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_objective = FraudDetection(\n",
    "    retry_percentage=.5,\n",
    "    interchange_fee=.02,\n",
    "    fraud_payout_percentage=.75,\n",
    "    amount_col='amount'  # column in data that contains the amount of the transaction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for best modeling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric data before running AutoClassifer\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'bool']\n",
    "X = X.select_dtypes(include=numerics)\n",
    "X_train, X_holdout, y_train, y_holdout = split_data(X, y, test_size=.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the fraud labels are binary, we will use `AutoClassifier`. When we call `.fit()`, the search for the best pipeline will begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for Fraud Detection. Lower score is better.\n",
      "\n",
      "Searching up to 10 pipelines. Will stop searching for new pipelines after 120 seconds.\n",
      "\n",
      "Possible model types: random_forest, xgboost, linear_model\n",
      "\n",
      "Testing Random Forest w/ imputation:  90%|█████████ | 9/10 [02:16<00:20, 20.90s/it]               \n",
      "\n",
      "Max time elapsed. Stopping search early.\n",
      "Testing Random Forest w/ imputation:  90%|█████████ | 9/10 [02:16<00:15, 15.21s/it]\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "clf = evalml.AutoClassifier(objective=fraud_objective,\n",
    "                            max_time=120,\n",
    "                            max_pipelines=10)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View rankings and select pipeline\n",
    "\n",
    "Once the fitting process is done, we can see all of the pipelines that were searched, ranked by their score on the objective function we defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>2575489.89</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>RFPipeline</td>\n",
       "      <td>9811919.99</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 715, 'max_depth': 487, 'imput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RFPipeline</td>\n",
       "      <td>10145930.53</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 630, 'imput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>RFPipeline</td>\n",
       "      <td>10236621.51</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 609, 'max_depth': 71, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>RFPipeline</td>\n",
       "      <td>11372831.59</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 859, 'max_depth': 678, 'imput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>11610654.75</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>11610654.75</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>RFPipeline</td>\n",
       "      <td>11610654.75</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 369, 'max_depth': 10, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>11610654.75</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name        score  high_variance_cv  \\\n",
       "0   2  LogisticRegressionPipeline   2575489.89             False   \n",
       "1   7                  RFPipeline   9811919.99             False   \n",
       "2   1                  RFPipeline  10145930.53             False   \n",
       "3   5                  RFPipeline  10236621.51             False   \n",
       "4   8                  RFPipeline  11372831.59             False   \n",
       "5   0             XGBoostPipeline  11610654.75             False   \n",
       "6   3             XGBoostPipeline  11610654.75             False   \n",
       "7   4                  RFPipeline  11610654.75             False   \n",
       "8   6             XGBoostPipeline  11610654.75             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "1  {'n_estimators': 715, 'max_depth': 487, 'imput...  \n",
       "2  {'n_estimators': 569, 'max_depth': 630, 'imput...  \n",
       "3  {'n_estimators': 609, 'max_depth': 71, 'impute...  \n",
       "4  {'n_estimators': 859, 'max_depth': 678, 'imput...  \n",
       "5  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "6  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "7  {'n_estimators': 369, 'max_depth': 10, 'impute...  \n",
       "8  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to select the best pipeline we can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = clf.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to select another pipeline we can use the id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = clf.get_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe pipeline\n",
    "\n",
    "You can get more details about any pipeline. Including how it performed on other objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************\u001b[0m\n",
      "\u001b[1m* Pipeline Description *\u001b[0m\n",
      "\u001b[1m************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost w/ imputation\n",
      "Model type: xgboost\n",
      "Objective: Fraud Detection (lower is better)\n",
      "Total training time (including CV): 3.7 seconds\n",
      "\n",
      "Parameters\n",
      "==========\n",
      "• eta: 0.5928446182250184\n",
      "• min_child_weight: 8.598391737229157\n",
      "• max_depth: 4\n",
      "• impute_strategy: most_frequent\n",
      "• percent_features: 0.6273280598181127\n",
      "\n",
      "Cross Validation\n",
      "=================\n",
      "        F1  Precision  Recall   AUC  Log Loss  Fraud Detection\n",
      "0    0.813      1.000   0.813 0.842     1.653     10811263.500\n",
      "1    0.812      1.000   0.812 0.842     1.658     10677483.750\n",
      "2    0.799      1.000   0.799 0.833     1.756     11610654.750\n",
      "mean 0.808      1.000   0.808 0.839     1.689     11033134.000\n",
      "std  0.008      0.000   0.008 0.006     0.058       504600.751\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on hold out\n",
    "\n",
    "Finally, we retrain the best pipeline on all of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.xgboost.XGBoostPipeline at 0x110e8d5c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can score the pipeline on the hold out data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138287376.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.score(X_holdout, y_holdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
